{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "057ef8e4-d8bd-4dcc-9e7f-c4f9057b30e2",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8f631bf4-9e87-4716-933e-2f53fdabdd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed26910d-00b7-48f3-bd3d-22575f3826aa",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ecce9cdd-6188-4549-a1c3-f927cc3f830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_data = pd.read_csv('California_Houses.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a80a04-3620-49fd-a3f4-31c9ea00f71d",
   "metadata": {},
   "source": [
    "# Informations about the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28545465-1548-47d6-85de-618746251d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (20640, 14)\n",
      "\n",
      "First few rows of the dataset:\n",
      "   Median_House_Value  Median_Income  Median_Age  Tot_Rooms  Tot_Bedrooms  \\\n",
      "0            452600.0         8.3252          41        880           129   \n",
      "1            358500.0         8.3014          21       7099          1106   \n",
      "2            352100.0         7.2574          52       1467           190   \n",
      "3            341300.0         5.6431          52       1274           235   \n",
      "4            342200.0         3.8462          52       1627           280   \n",
      "\n",
      "   Population  Households  Latitude  Longitude  Distance_to_coast  \\\n",
      "0         322         126     37.88    -122.23        9263.040773   \n",
      "1        2401        1138     37.86    -122.22       10225.733072   \n",
      "2         496         177     37.85    -122.24        8259.085109   \n",
      "3         558         219     37.85    -122.25        7768.086571   \n",
      "4         565         259     37.85    -122.25        7768.086571   \n",
      "\n",
      "   Distance_to_LA  Distance_to_SanDiego  Distance_to_SanJose  \\\n",
      "0   556529.158342         735501.806984         67432.517001   \n",
      "1   554279.850069         733236.884360         65049.908574   \n",
      "2   554610.717069         733525.682937         64867.289833   \n",
      "3   555194.266086         734095.290744         65287.138412   \n",
      "4   555194.266086         734095.290744         65287.138412   \n",
      "\n",
      "   Distance_to_SanFrancisco  \n",
      "0              21250.213767  \n",
      "1              20880.600400  \n",
      "2              18811.487450  \n",
      "3              18031.047568  \n",
      "4              18031.047568  \n",
      "\n",
      "Column information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 14 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Median_House_Value        20640 non-null  float64\n",
      " 1   Median_Income             20640 non-null  float64\n",
      " 2   Median_Age                20640 non-null  int64  \n",
      " 3   Tot_Rooms                 20640 non-null  int64  \n",
      " 4   Tot_Bedrooms              20640 non-null  int64  \n",
      " 5   Population                20640 non-null  int64  \n",
      " 6   Households                20640 non-null  int64  \n",
      " 7   Latitude                  20640 non-null  float64\n",
      " 8   Longitude                 20640 non-null  float64\n",
      " 9   Distance_to_coast         20640 non-null  float64\n",
      " 10  Distance_to_LA            20640 non-null  float64\n",
      " 11  Distance_to_SanDiego      20640 non-null  float64\n",
      " 12  Distance_to_SanJose       20640 non-null  float64\n",
      " 13  Distance_to_SanFrancisco  20640 non-null  float64\n",
      "dtypes: float64(9), int64(5)\n",
      "memory usage: 2.2 MB\n",
      "None\n",
      "\n",
      "Summary statistics:\n",
      "       Median_House_Value  Median_Income    Median_Age     Tot_Rooms  \\\n",
      "count        20640.000000   20640.000000  20640.000000  20640.000000   \n",
      "mean        206855.816909       3.870671     28.639486   2635.763081   \n",
      "std         115395.615874       1.899822     12.585558   2181.615252   \n",
      "min          14999.000000       0.499900      1.000000      2.000000   \n",
      "25%         119600.000000       2.563400     18.000000   1447.750000   \n",
      "50%         179700.000000       3.534800     29.000000   2127.000000   \n",
      "75%         264725.000000       4.743250     37.000000   3148.000000   \n",
      "max         500001.000000      15.000100     52.000000  39320.000000   \n",
      "\n",
      "       Tot_Bedrooms    Population    Households      Latitude     Longitude  \\\n",
      "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \n",
      "mean     537.898014   1425.476744    499.539680     35.631861   -119.569704   \n",
      "std      421.247906   1132.462122    382.329753      2.135952      2.003532   \n",
      "min        1.000000      3.000000      1.000000     32.540000   -124.350000   \n",
      "25%      295.000000    787.000000    280.000000     33.930000   -121.800000   \n",
      "50%      435.000000   1166.000000    409.000000     34.260000   -118.490000   \n",
      "75%      647.000000   1725.000000    605.000000     37.710000   -118.010000   \n",
      "max     6445.000000  35682.000000   6082.000000     41.950000   -114.310000   \n",
      "\n",
      "       Distance_to_coast  Distance_to_LA  Distance_to_SanDiego  \\\n",
      "count       20640.000000    2.064000e+04          2.064000e+04   \n",
      "mean        40509.264883    2.694220e+05          3.981649e+05   \n",
      "std         49140.039160    2.477324e+05          2.894006e+05   \n",
      "min           120.676447    4.205891e+02          4.849180e+02   \n",
      "25%          9079.756762    3.211125e+04          1.594264e+05   \n",
      "50%         20522.019101    1.736675e+05          2.147398e+05   \n",
      "75%         49830.414479    5.271562e+05          7.057954e+05   \n",
      "max        333804.686371    1.018260e+06          1.196919e+06   \n",
      "\n",
      "       Distance_to_SanJose  Distance_to_SanFrancisco  \n",
      "count         20640.000000              20640.000000  \n",
      "mean         349187.551219             386688.422291  \n",
      "std          217149.875026             250122.192316  \n",
      "min             569.448118                456.141313  \n",
      "25%          113119.928682             117395.477505  \n",
      "50%          459758.877000             526546.661701  \n",
      "75%          516946.490963             584552.007907  \n",
      "max          836762.678210             903627.663298  \n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Shape:\", housing_data.shape)\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "print(housing_data.head())\n",
    "print(\"\\nColumn information:\")\n",
    "print(housing_data.info())\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(housing_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7162df86-e527-4402-92c3-9d92789b1d2b",
   "metadata": {},
   "source": [
    "# Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "51505524-b588-4702-9ace-3f7a487d790e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median_House_Value          0\n",
      "Median_Income               0\n",
      "Median_Age                  0\n",
      "Tot_Rooms                   0\n",
      "Tot_Bedrooms                0\n",
      "Population                  0\n",
      "Households                  0\n",
      "Latitude                    0\n",
      "Longitude                   0\n",
      "Distance_to_coast           0\n",
      "Distance_to_LA              0\n",
      "Distance_to_SanDiego        0\n",
      "Distance_to_SanJose         0\n",
      "Distance_to_SanFrancisco    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(housing_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7beda35-a832-4633-8b9a-a3587bd102ff",
   "metadata": {},
   "source": [
    "# Split the data into features and target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5285ab94-0934-49cc-bd5f-07d707df5379",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_housing = housing_data.drop('Median_House_Value', axis=1)\n",
    "y_housing = housing_data['Median_House_Value']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2fac56-2677-40f5-92f1-c1cc09b6a027",
   "metadata": {},
   "source": [
    "# Split the data into training (70%), validation (15%), and testing (15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "134d0139-8ea1-4664-97b4-be3793e0c856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_h, X_temp_h, y_train_h, y_temp_h = train_test_split(X_housing, y_housing, test_size=0.3, random_state=42)\n",
    "X_val_h, X_test_h, y_val_h, y_test_h = train_test_split(X_temp_h, y_temp_h, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9d12be-bd05-42cb-8dfb-ea2183dff2a7",
   "metadata": {},
   "source": [
    "# Data Split Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c54466a-f4a2-4b08-90c0-2ae3d119966f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 14448 samples\n",
      "Validation set: 3096 samples\n",
      "Testing set: 3096 samples\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set: {X_train_h.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val_h.shape[0]} samples\")\n",
    "print(f\"Testing set: {X_test_h.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b974a76-e179-4c9a-a075-33c0e5fdcc73",
   "metadata": {},
   "source": [
    "\n",
    "### z-score normalization \n",
    "After z-score normalization, all features will have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "All values are adjusted as shown in this formula:\n",
    "$$x^{(i)}_j = \\dfrac{x^{(i)}_j - \\mu_j}{\\sigma_j} $$ \n",
    "where $j$ selects a feature or a column in the $\\mathbf{X}$ matrix. $µ_j$ is the mean of all the values for feature (j) and $\\sigma_j$ is the standard deviation of feature (j).\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mu_j &= \\frac{1}{m} \\sum_{i=0}^{m-1} x^{(i)}_j \\\\\n",
    "\\sigma^2_j &= \\frac{1}{m} \\sum_{i=0}^{m-1} (x^{(i)}_j - \\mu_j)^2  \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14053bd6-6383-4344-b896-c5fdd785aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore_normalize_features(X):\n",
    "    \"\"\"\n",
    "    computes  X, zcore normalized by column\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n))     : input data, m examples, n features\n",
    "      \n",
    "    Returns:\n",
    "      X_norm (ndarray (m,n)): input normalized by column\n",
    "      mu (ndarray (n,))     : mean of each feature\n",
    "      sigma (ndarray (n,))  : standard deviation of each feature\n",
    "    \"\"\"\n",
    "    # find the mean of each column/feature\n",
    "    mu     = np.mean(X, axis=0)                 # mu will have shape (n,)\n",
    "    # find the standard deviation of each column/feature\n",
    "    sigma  = np.std(X, axis=0)                  # sigma will have shape (n,)\n",
    "    # element-wise, subtract mu for that column from each example, divide by std for that column\n",
    "    X_norm = (X - mu) / sigma      \n",
    "\n",
    "    return (X_norm, mu, sigma)\n",
    " \n",
    "#check our work\n",
    "#from sklearn.preprocessing import scale\n",
    "#scale(X_orig, axis=0, with_mean=True, with_std=True, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "56a404bd-8755-4b73-a9bf-e6b1b3d98c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_h_scaled, mu, sigma = zscore_normalize_features(X_train_h)\n",
    "\n",
    "# Apply the same transformation to validation and test sets using training data statistics\n",
    "X_val_h_scaled = (X_val_h - mu) / sigma\n",
    "X_test_h_scaled = (X_test_h - mu) / sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7e9b5a-3a5c-443b-b209-ff088e90c86c",
   "metadata": {},
   "source": [
    "# Applying Linear Regression\n",
    "## Define gradient descent function for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e4ffce4d-a40c-4431-bb4c-2a7b26e21ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w, b):\n",
    "    \"\"\"\n",
    "    Compute the Mean Squared Error (MSE) cost function.\n",
    "    \"\"\"\n",
    "    m = X.shape[0]  # Number of training examples\n",
    "    predictions = np.dot(X, w) + b\n",
    "    cost = np.sum((predictions - y) ** 2) / (2 * m)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3d29ea2a-0cfc-4d59-ac1d-acd6c5d86364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b):\n",
    "    \"\"\"\n",
    "    Compute gradients for linear regression parameters.\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    predictions = np.dot(X, w) + b\n",
    "    errors = predictions - y\n",
    "    dj_dw = np.dot(X.T, errors) / m\n",
    "    dj_db = np.sum(errors) / m\n",
    "    return dj_dw, dj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "07beb73f-64d3-4eae-acb2-31278334ee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w, b, alpha, num_iters):\n",
    "    \"\"\"\n",
    "    Perform batch gradient descent to optimize w and b.\n",
    "    \"\"\"\n",
    "    cost_history = []\n",
    "    for i in range(num_iters):\n",
    "        dj_dw, dj_db = compute_gradient(X, y, w, b)\n",
    "        w -= alpha * dj_dw\n",
    "        b -= alpha * dj_db\n",
    "        cost = compute_cost(X, y, w, b)\n",
    "        cost_history.append(cost)\n",
    "        \n",
    "        if i % (num_iters // 10) == 0:\n",
    "            print(f\"Iteration {i}: Cost {cost:.4f}\")\n",
    "    \n",
    "    return w, b, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fcb42169-fea5-4ed3-8d62-6cfc7f3d64e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, b):\n",
    "    \"\"\"\n",
    "    Generate predictions using learned parameters.\n",
    "    \"\"\"\n",
    "    return np.dot(X, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "825ddb87-fe06-48f0-a841-7913461a2b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Cost 27577059994.2481\n",
      "Iteration 100: Cost 5787675817.6725\n",
      "Iteration 200: Cost 3016082442.8218\n",
      "Iteration 300: Cost 2622011229.5397\n",
      "Iteration 400: Cost 2544073247.7819\n",
      "Iteration 500: Cost 2513840526.1874\n",
      "Iteration 600: Cost 2494182868.4871\n",
      "Iteration 700: Cost 2479040929.6061\n",
      "Iteration 800: Cost 2466857016.7979\n",
      "Iteration 900: Cost 2456889302.2467\n",
      "\n",
      "Validation Set:\n",
      "Mean Squared Error: 5099618793.24\n",
      "Mean Absolute Error: 52316.48\n",
      "Root Mean Squared Error: 71411.62\n",
      "\n",
      "Test Set:\n",
      "Mean Squared Error: 4585260876.30\n",
      "Mean Absolute Error: 50393.83\n",
      "Root Mean Squared Error: 67714.55\n"
     ]
    }
   ],
   "source": [
    "# Initialize model parameters\n",
    "w_init = np.zeros(X_train_h_scaled.shape[1])\n",
    "b_init = 0.0\n",
    "alpha = 0.01  # Learning rate\n",
    "iterations = 1000  # Number of iterations\n",
    "\n",
    "# Train the model\n",
    "w_final, b_final, cost_history = gradient_descent(X_train_h_scaled, y_train_h, w_init, b_init, alpha, iterations)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = predict(X_val_h_scaled, w_final, b_final)\n",
    "\n",
    "# Compute performance metrics\n",
    "mse_val = np.mean((y_val_pred - y_val_h) ** 2)\n",
    "mae_val = np.mean(np.abs(y_val_pred - y_val_h))\n",
    "rmse_val = np.sqrt(mse_val)\n",
    "\n",
    "print(\"\\nValidation Set:\")\n",
    "print(f\"Mean Squared Error: {mse_val:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae_val:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse_val:.2f}\")\n",
    "\n",
    "# Test the model on the test set\n",
    "y_test_pred = predict(X_test_h_scaled, w_final, b_final)\n",
    "\n",
    "# Compute test performance metrics\n",
    "mse_test = np.mean((y_test_pred - y_test_h) ** 2)\n",
    "mae_test = np.mean(np.abs(y_test_pred - y_test_h))\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "print(\"\\nTest Set:\")\n",
    "print(f\"Mean Squared Error: {mse_test:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae_test:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse_test:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d225799-034c-44b5-8f56-c1eb77754eec",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "# Applying Lasso Regression (L1 Regularization)\n",
    "\n",
    "Lasso regression adds L1 regularization to linear regression, which penalizes large coefficients using the sum of their absolute values. This promotes sparsity in the model and can be used for feature selection.\n",
    "\n",
    "$$ \\text{Cost} = MSE + \\alpha \\sum_{j=1}^{n} |w_j| $$\n",
    "\n",
    "Where:\n",
    "- MSE is the mean squared error\n",
    "- $\\alpha$ is the regularization strength\n",
    "- $w_j$ are the feature weights\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "89f2c126-027f-4ac8-876d-a58dacb8522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lasso_models(X_train, y_train, X_val, y_val):\n",
    "    alpha_values = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "    best_alpha = None\n",
    "    best_val_mse = float('inf')\n",
    "    lasso_results = []\n",
    "    \n",
    "    for alpha in alpha_values:\n",
    "        lasso_model = Lasso(alpha=alpha, max_iter=10000)\n",
    "        lasso_model.fit(X_train, y_train)\n",
    "        y_val_pred = lasso_model.predict(X_val)\n",
    "        \n",
    "        val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "        val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "        val_rmse = np.sqrt(val_mse)\n",
    "        \n",
    "        lasso_results.append({\n",
    "            'alpha': alpha,\n",
    "            'validation_mse': val_mse,\n",
    "            'validation_mae': val_mae,\n",
    "            'validation_rmse': val_rmse\n",
    "        })\n",
    "        \n",
    "        print(f\"Lasso (alpha={alpha}):\")\n",
    "        print(f\"  Validation MSE: {val_mse:.2f}\")\n",
    "        print(f\"  Validation MAE: {val_mae:.2f}\")\n",
    "        print(f\"  Validation RMSE: {val_rmse:.2f}\")\n",
    "        \n",
    "        if val_mse < best_val_mse:\n",
    "            best_val_mse = val_mse\n",
    "            best_alpha = alpha\n",
    "    \n",
    "    print(f\"\\nBest Lasso alpha: {best_alpha} with Validation MSE: {best_val_mse:.2f}\")\n",
    "    return best_alpha, lasso_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "de04579f-57af-482a-86d6-3a6ed55b6e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso (alpha=0.001):\n",
      "  Validation MSE: 4907212012.46\n",
      "  Validation MAE: 50790.06\n",
      "  Validation RMSE: 70051.50\n",
      "Lasso (alpha=0.01):\n",
      "  Validation MSE: 4907212148.34\n",
      "  Validation MAE: 50790.07\n",
      "  Validation RMSE: 70051.50\n",
      "Lasso (alpha=0.1):\n",
      "  Validation MSE: 4907213520.76\n",
      "  Validation MAE: 50790.13\n",
      "  Validation RMSE: 70051.51\n",
      "Lasso (alpha=1.0):\n",
      "  Validation MSE: 4907228606.53\n",
      "  Validation MAE: 50790.78\n",
      "  Validation RMSE: 70051.61\n",
      "Lasso (alpha=10.0):\n",
      "  Validation MSE: 4907515542.92\n",
      "  Validation MAE: 50797.43\n",
      "  Validation RMSE: 70053.66\n",
      "Lasso (alpha=100.0):\n",
      "  Validation MSE: 4923933009.24\n",
      "  Validation MAE: 50975.80\n",
      "  Validation RMSE: 70170.74\n",
      "\n",
      "Best Lasso alpha: 0.001 with Validation MSE: 4907212012.46\n",
      "\n",
      "Lasso Regression (alpha=0.001) - Final Results:\n",
      "\n",
      "Validation Set:\n",
      "Mean Squared Error: 4907212012.46\n",
      "Mean Absolute Error: 50790.06\n",
      "Root Mean Squared Error: 70051.50\n",
      "\n",
      "Test Set:\n",
      "Mean Squared Error: 4400953043.36\n",
      "Mean Absolute Error: 48782.03\n",
      "Root Mean Squared Error: 66339.68\n"
     ]
    }
   ],
   "source": [
    "best_lasso_alpha, lasso_results = train_lasso_models(X_train_h_scaled, y_train_h, X_val_h_scaled, y_val_h)\n",
    "\n",
    "# Train the best Lasso model and evaluate on test set\n",
    "best_lasso_model = Lasso(alpha=best_lasso_alpha, max_iter=10000)\n",
    "best_lasso_model.fit(X_train_h_scaled, y_train_h)\n",
    "\n",
    "# Make predictions with best Lasso model\n",
    "y_val_pred_lasso = best_lasso_model.predict(X_val_h_scaled)\n",
    "y_test_pred_lasso = best_lasso_model.predict(X_test_h_scaled)\n",
    "\n",
    "# Compute performance metrics for validation set\n",
    "mse_val_lasso = mean_squared_error(y_val_h, y_val_pred_lasso)\n",
    "mae_val_lasso = mean_absolute_error(y_val_h, y_val_pred_lasso)\n",
    "rmse_val_lasso = np.sqrt(mse_val_lasso)\n",
    "\n",
    "# Compute performance metrics for test set\n",
    "mse_test_lasso = mean_squared_error(y_test_h, y_test_pred_lasso)\n",
    "mae_test_lasso = mean_absolute_error(y_test_h, y_test_pred_lasso)\n",
    "rmse_test_lasso = np.sqrt(mse_test_lasso)\n",
    "\n",
    "print(f\"\\nLasso Regression (alpha={best_lasso_alpha}) - Final Results:\")\n",
    "print(\"\\nValidation Set:\")\n",
    "print(f\"Mean Squared Error: {mse_val_lasso:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae_val_lasso:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse_val_lasso:.2f}\")\n",
    "\n",
    "print(\"\\nTest Set:\")\n",
    "print(f\"Mean Squared Error: {mse_test_lasso:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae_test_lasso:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse_test_lasso:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eb09fa-aca1-4162-9ab1-67764593ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ridge_models(X_train, y_train, X_val, y_val): \n",
    "    alpha_values = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0] \n",
    "    best_alpha = None \n",
    "    best_val_mse = float('inf') \n",
    "    ridge_results = [] \n",
    "     \n",
    "    for alpha in alpha_values: \n",
    "        ridge_model = Ridge(alpha=alpha, max_iter=10000) \n",
    "        ridge_model.fit(X_train, y_train) \n",
    "        y_val_pred = ridge_model.predict(X_val) \n",
    "         \n",
    "        val_mse = mean_squared_error(y_val, y_val_pred) \n",
    "        val_mae = mean_absolute_error(y_val, y_val_pred) \n",
    "        val_rmse = np.sqrt(val_mse) \n",
    "         \n",
    "        ridge_results.append({ \n",
    "            'alpha': alpha, \n",
    "            'validation_mse': val_mse, \n",
    "            'validation_mae': val_mae, \n",
    "            'validation_rmse': val_rmse \n",
    "        }) \n",
    "         \n",
    "        print(f\"Ridge (alpha={alpha}):\") \n",
    "        print(f\"  Validation MSE: {val_mse:.2f}\") \n",
    "        print(f\"  Validation MAE: {val_mae:.2f}\") \n",
    "        print(f\"  Validation RMSE: {val_rmse:.2f}\") \n",
    "         \n",
    "        if val_mse < best_val_mse: \n",
    "            best_val_mse = val_mse \n",
    "            best_alpha = alpha \n",
    "     \n",
    "    print(f\"\\nBest Ridge alpha: {best_alpha} with Validation MSE: {best_val_mse:.2f}\") \n",
    "    return best_alpha, ridge_results\n",
    "\n",
    "best_ridge_alpha, ridge_results = train_ridge_models(X_train_h_scaled, y_train_h, X_val_h_scaled, y_val_h) \n",
    " \n",
    "# Train the best Ridge model and evaluate on test set \n",
    "best_ridge_model = Ridge(alpha=best_ridge_alpha, max_iter=10000) \n",
    "best_ridge_model.fit(X_train_h_scaled, y_train_h) \n",
    " \n",
    "# Make predictions with best Ridge model \n",
    "y_val_pred_ridge = best_ridge_model.predict(X_val_h_scaled) \n",
    "y_test_pred_ridge = best_ridge_model.predict(X_test_h_scaled) \n",
    " \n",
    "# Compute performance metrics for validation set \n",
    "mse_val_ridge = mean_squared_error(y_val_h, y_val_pred_ridge) \n",
    "mae_val_ridge = mean_absolute_error(y_val_h, y_val_pred_ridge) \n",
    "rmse_val_ridge = np.sqrt(mse_val_ridge) \n",
    " \n",
    "# Compute performance metrics for test set \n",
    "mse_test_ridge = mean_squared_error(y_test_h, y_test_pred_ridge) \n",
    "mae_test_ridge = mean_absolute_error(y_test_h, y_test_pred_ridge) \n",
    "rmse_test_ridge = np.sqrt(mse_test_ridge) \n",
    " \n",
    "print(f\"\\nRidge Regression (alpha={best_ridge_alpha}) - Final Results:\") \n",
    "print(\"\\nValidation Set:\") \n",
    "print(f\"Mean Squared Error: {mse_val_ridge:.2f}\") \n",
    "print(f\"Mean Absolute Error: {mae_val_ridge:.2f}\") \n",
    "print(f\"Root Mean Squared Error: {rmse_val_ridge:.2f}\") \n",
    " \n",
    "print(\"\\nTest Set:\") \n",
    "print(f\"Mean Squared Error: {mse_test_ridge:.2f}\") \n",
    "print(f\"Mean Absolute Error: {mae_test_ridge:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse_test_ridge:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
